<!DOCTYPE html>
<html lang="english"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="shortcut icon" type="image/png" href="/assets/images/favicon.png"/><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>A large-scale study on research code quality and execution | French Reproducible Research Network</title>
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="A large-scale study on research code quality and execution" />
<meta name="author" content="Recherche Reproductible" />
<meta property="og:locale" content="english" />
<meta name="description" content="This article presents a study on the quality and execution of research code from publicly-available replication datasets at the Harvard Dataverse repository. Research code is typically created by a group of scientists and published together with academic papers to facilitate research transparency and reproducibility. For this study, we define ten questions to address aspects impacting research reproducibility and reuse. First, we retrieve and analyze more than 2000 replication datasets with over 9000 unique R files published from 2010 to 2020. Second, we execute the code in a clean runtime environment to assess its ease of reuse. Common coding errors were identified, and some of them were solved with automatic code cleaning to aid code execution. We find that 74% of R files failed to complete without error in the initial execution, while 56% failed when code cleaning was applied, showing that many errors can be prevented with good coding practices. We also analyze the replication datasets from journals’ collections and discuss the impact of the journal policy strictness on the code re-execution rate. Finally, based on our results, we propose a set of recommendations for code dissemination aimed at researchers, journals, and repositories." />
<meta property="og:description" content="This article presents a study on the quality and execution of research code from publicly-available replication datasets at the Harvard Dataverse repository. Research code is typically created by a group of scientists and published together with academic papers to facilitate research transparency and reproducibility. For this study, we define ten questions to address aspects impacting research reproducibility and reuse. First, we retrieve and analyze more than 2000 replication datasets with over 9000 unique R files published from 2010 to 2020. Second, we execute the code in a clean runtime environment to assess its ease of reuse. Common coding errors were identified, and some of them were solved with automatic code cleaning to aid code execution. We find that 74% of R files failed to complete without error in the initial execution, while 56% failed when code cleaning was applied, showing that many errors can be prevented with good coding practices. We also analyze the replication datasets from journals’ collections and discuss the impact of the journal policy strictness on the code re-execution rate. Finally, based on our results, we propose a set of recommendations for code dissemination aimed at researchers, journals, and repositories." />
<link rel="canonical" href="https://www.recherche-reproductible.fr//publication/2022/02/21/large-scale-study.html" />
<meta property="og:url" content="https://www.recherche-reproductible.fr//publication/2022/02/21/large-scale-study.html" />
<meta property="og:site_name" content="French Reproducible Research Network" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-02-21T17:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="A large-scale study on research code quality and execution" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Recherche Reproductible"},"dateModified":"2022-02-21T17:00:00+00:00","datePublished":"2022-02-21T17:00:00+00:00","description":"This article presents a study on the quality and execution of research code from publicly-available replication datasets at the Harvard Dataverse repository. Research code is typically created by a group of scientists and published together with academic papers to facilitate research transparency and reproducibility. For this study, we define ten questions to address aspects impacting research reproducibility and reuse. First, we retrieve and analyze more than 2000 replication datasets with over 9000 unique R files published from 2010 to 2020. Second, we execute the code in a clean runtime environment to assess its ease of reuse. Common coding errors were identified, and some of them were solved with automatic code cleaning to aid code execution. We find that 74% of R files failed to complete without error in the initial execution, while 56% failed when code cleaning was applied, showing that many errors can be prevented with good coding practices. We also analyze the replication datasets from journals’ collections and discuss the impact of the journal policy strictness on the code re-execution rate. Finally, based on our results, we propose a set of recommendations for code dissemination aimed at researchers, journals, and repositories.","headline":"A large-scale study on research code quality and execution","mainEntityOfPage":{"@type":"WebPage","@id":"https://www.recherche-reproductible.fr//publication/2022/02/21/large-scale-study.html"},"url":"https://www.recherche-reproductible.fr//publication/2022/02/21/large-scale-study.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://www.recherche-reproductible.fr//feed.xml" title="French Reproducible Research Network" />
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/"><img alt="French Reproducible Research Network" src="/assets/images/FRRN_logo_small.png"/></a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><div style="float:left;">
            <a class="page-link" href="/community/">Communauté</a>
            <div class="subpage-menu"><a class="subpage-link" href="/steering/">Structure, collèges et GTs</a><a class="subpage-link" href="/international/">Réseaux internationaux</a><a class="subpage-link" href="/initiatives/">Initiatives nationales</a><a class="subpage-link" href="/initiatives-internationales/">Initiatives internationales</a></div>
            </div><div style="float:left;">
            <a class="page-link" href="/activities/">Activités</a>
            <div class="subpage-menu"><a class="subpage-link" href="/webinars/">Wébinaires</a><a class="subpage-link" href="/publications/">Publications</a><a class="subpage-link" href="/training/">Formations</a></div>
            </div><div style="float:left;">
            <a class="page-link" href="/resources/">Ressources</a>
            <div class="subpage-menu"></div>
            </div><a class="page-link" href="/feed.xml"><svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg>
          </a><a class="site-logo" rel="author" href="https://www.enseignementsup-recherche.gouv.fr/fr"><img align=right width=150px alt="French Reproducible Research Network" src="/assets/images/mesr.png"/></a>

        </div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">A large-scale study on research code quality and execution</h1>
    <p class="post-meta"><time class="dt-published" datetime="2022-02-21T17:00:00+00:00" itemprop="datePublished">
        Feb 21, 2022
      </time></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>This article presents a study on the quality and execution of research code from publicly-available replication datasets at the Harvard Dataverse repository. Research code is typically created by a group of scientists and published together with academic papers to facilitate research transparency and reproducibility. For this study, we define ten questions to address aspects impacting research reproducibility and reuse. First, we retrieve and analyze more than 2000 replication datasets with over 9000 unique R files published from 2010 to 2020. Second, we execute the code in a clean runtime environment to assess its ease of reuse. Common coding errors were identified, and some of them were solved with automatic code cleaning to aid code execution. We find that 74% of R files failed to complete without error in the initial execution, while 56% failed when code cleaning was applied, showing that many errors can be prevented with good coding practices. We also analyze the replication datasets from journals’ collections and discuss the impact of the journal policy strictness on the code re-execution rate. Finally, based on our results, we propose a set of recommendations for code dissemination aimed at researchers, journals, and repositories.</p>

<p><a href="https://www.nature.com/articles/s41597-022-01143-6"><span id="Trisovic2022"><span style="font-variant: small-caps">Trisovic, A., Lau, M.K., Pasquier, T., and Crosas, M.</span> 2022. A large-scale study on research code quality and execution. <i>Scientific Data</i> <i>9</i>, 1.</span></a></p>

  </div><a class="u-url" href="/publication/2022/02/21/large-scale-study.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">
    <div class="footer-col-wrapper">
      <div class="footer-col">
        <b>French Reproducible Research Network</b><br/>
      </div>
      <div class="footer-col">
        <p>A national network of scientists for promoting reproducible research.</p>
      </div>
      <div class="footer-col">
        <a href="https://github.com/FR-RN/FR-RN">Sources</a><br>
        <a href="/credits">Legal notices</a>
      </div>
    </div>
  </div>
</footer>
</body>

</html>
