<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="https://www.recherche-reproductible.fr/FR-RN/feed.xml" rel="self" type="application/atom+xml" /><link href="https://www.recherche-reproductible.fr/FR-RN/" rel="alternate" type="text/html" /><updated>2023-01-13T18:36:43+00:00</updated><id>https://www.recherche-reproductible.fr/FR-RN/feed.xml</id><title type="html">Recherche Reproductible</title><subtitle>Un réseau national de chercheurs pour la promotion de la recherche reproductible.</subtitle><author><name>Recherche Reproductible</name></author><entry><title type="html">Recherche Reproductible: états des lieux</title><link href="https://www.recherche-reproductible.fr/FR-RN/event/2023/03/18/RR-Days.html" rel="alternate" type="text/html" title="Recherche Reproductible: états des lieux" /><published>2023-03-18T08:00:00+00:00</published><updated>2023-03-18T08:00:00+00:00</updated><id>https://www.recherche-reproductible.fr/FR-RN/event/2023/03/18/RR-Days</id><content type="html" xml:base="https://www.recherche-reproductible.fr/FR-RN/event/2023/03/18/RR-Days.html"><![CDATA[<p>Un nombre croissant de chercheurs s’intéresse à la problématique de la reproductibilité, dont la définition même peut grandement varier d’une discpline à une autre (observationnelle, expérimentale, statistique, computationnelle, …). Or, nous avons rarement l’occasion de poser un regard inter-disciplinaire sur nos approches et définitions respectives. Ce <a href="http://www.recherche-reproductible.fr/rr-days/">workshop</a> se veut donc un lieu d’échanges et d’information pour dresser un premier état des lieux de la reproductibilité en France. Le but n’est donc pas tant de faire de longs exposés, mais plutôt de favoriser les interventions courtes suivies de discussion permettant à tout un chacun de mieux comprendre les problématiques des autres en général et de la jeune génération (doctorants et post-doctorants) en particulier. Nous essayons donc de rassembler des scientifiques de toutes disciplines.</p>

<p>Plus d’informations sur: <a href="http://www.recherche-reproductible.fr/rr-days">www.recherche-reproductible.fr/rr-days</a></p>]]></content><author><name>Recherche Reproductible</name></author><category term="event" /><summary type="html"><![CDATA[Un nombre croissant de chercheurs s’intéresse à la problématique de la reproductibilité, dont la définition même peut grandement varier d’une discpline à une autre (observationnelle, expérimentale, statistique, computationnelle, …). Or, nous avons rarement l’occasion de poser un regard inter-disciplinaire sur nos approches et définitions respectives. Ce workshop se veut donc un lieu d’échanges et d’information pour dresser un premier état des lieux de la reproductibilité en France. Le but n’est donc pas tant de faire de longs exposés, mais plutôt de favoriser les interventions courtes suivies de discussion permettant à tout un chacun de mieux comprendre les problématiques des autres en général et de la jeune génération (doctorants et post-doctorants) en particulier. Nous essayons donc de rassembler des scientifiques de toutes disciplines.]]></summary></entry><entry xml:lang="english"><title type="html">The reproducibility issues that haunt health-care AI</title><link href="https://www.recherche-reproductible.fr/FR-RN/publication/2023/01/13/Health-AI.html" rel="alternate" type="text/html" title="The reproducibility issues that haunt health-care AI" /><published>2023-01-13T08:00:00+00:00</published><updated>2023-01-13T08:00:00+00:00</updated><id>https://www.recherche-reproductible.fr/FR-RN/publication/2023/01/13/Health-AI</id><content type="html" xml:base="https://www.recherche-reproductible.fr/FR-RN/publication/2023/01/13/Health-AI.html"><![CDATA[<p>Health-care systems are rolling out artificial-intelligence tools for
diagnosis and monitoring. But how reliable are the models?</p>

<p>Each day, around 350 people in the United States die from lung cancer. Many of those deaths could be prevented by screening with low-dose computed tomography (CT) scans. But scanning millions of people would produce millions of images, and there aren’t enough radiologists to do the work. Even if there were, specialists regularly disagree about whether images show cancer or not. The 2017 Kaggle Data Science Bowl set out to test whether machine-learning algorithms could fill the gap.</p>

<p><a href="https://www.nature.com/articles/d41586-023-00023-2"><span id="Sohn:2023"><span style="font-variant: small-caps">Sohn, E.</span> 2023. The reproducibility issues that haunt health-care AI. <i>Nature</i> <i>613</i>, 7943, 402–403.</span></a></p>]]></content><author><name>Recherche Reproductible</name></author><category term="publication" /><category term="medicine," /><category term="artificial" /><category term="intelligence" /><summary type="html"><![CDATA[Health-care systems are rolling out artificial-intelligence tools for diagnosis and monitoring. But how reliable are the models?]]></summary></entry><entry><title type="html">Graphics Replicability Stamp Initiative (GRSI)</title><link href="https://www.recherche-reproductible.fr/FR-RN/news/2023/01/13/Graphics-Replicability-Stamps.html" rel="alternate" type="text/html" title="Graphics Replicability Stamp Initiative (GRSI)" /><published>2023-01-13T07:00:00+00:00</published><updated>2023-01-13T07:00:00+00:00</updated><id>https://www.recherche-reproductible.fr/FR-RN/news/2023/01/13/Graphics-Replicability-Stamps</id><content type="html" xml:base="https://www.recherche-reproductible.fr/FR-RN/news/2023/01/13/Graphics-Replicability-Stamps.html"><![CDATA[<p>The <a href="http://www.replicabilitystamp.org/">Graphics Replicability Stamp Initiative (GRSI)</a> is an independent group of volunteers who help the community by enabling sharing of code and data as a community resource for non-commercial use. The volunteers check the submitted code and certify its replicability, awarding a replicability stamp, which is an additional recognition for authors of accepted papers who are willing to provide a complete implementation of their algorithm, to replicate the results presented in their paper. The replicability stamp is not meant to be a measure of the scientiﬁc quality of the paper or of the usefulness of presented algorithms. Rather, it is meant to be an endorsement of the replicability of the results presented in the paper and the recognition of the service provided to the community by releasing the code. Submissions for the replicability stamp will be considered only <em>after</em> the paper has been fully accepted. Submissions that are awarded the replicability stamp will receive additional exposure by being listed on this website. The purpose of this stamp is to promote reproducibility of research results and to allow scientists and practitioners to immediately beneﬁt from state-of-the-art research results, without spending months re-implementing the proposed algorithms and trying to ﬁnd the right parameter values. We also hope that it will indirectly foster scientiﬁc progress, since it will allow researchers to reliably compare with and to build upon existing techniques, knowing that they are using exactly the same implementation.</p>]]></content><author><name>Recherche Reproductible</name></author><category term="news" /><summary type="html"><![CDATA[The Graphics Replicability Stamp Initiative (GRSI) is an independent group of volunteers who help the community by enabling sharing of code and data as a community resource for non-commercial use. The volunteers check the submitted code and certify its replicability, awarding a replicability stamp, which is an additional recognition for authors of accepted papers who are willing to provide a complete implementation of their algorithm, to replicate the results presented in their paper. The replicability stamp is not meant to be a measure of the scientiﬁc quality of the paper or of the usefulness of presented algorithms. Rather, it is meant to be an endorsement of the replicability of the results presented in the paper and the recognition of the service provided to the community by releasing the code. Submissions for the replicability stamp will be considered only after the paper has been fully accepted. Submissions that are awarded the replicability stamp will receive additional exposure by being listed on this website. The purpose of this stamp is to promote reproducibility of research results and to allow scientists and practitioners to immediately beneﬁt from state-of-the-art research results, without spending months re-implementing the proposed algorithms and trying to ﬁnd the right parameter values. We also hope that it will indirectly foster scientiﬁc progress, since it will allow researchers to reliably compare with and to build upon existing techniques, knowing that they are using exactly the same implementation.]]></summary></entry><entry><title type="html">Workshop on Reproducibility in Cancer Biology [en]</title><link href="https://www.recherche-reproductible.fr/FR-RN/event/2023/01/11/Cancer-Biology.html" rel="alternate" type="text/html" title="Workshop on Reproducibility in Cancer Biology [en]" /><published>2023-01-11T08:00:00+00:00</published><updated>2023-01-11T08:00:00+00:00</updated><id>https://www.recherche-reproductible.fr/FR-RN/event/2023/01/11/Cancer-Biology</id><content type="html" xml:base="https://www.recherche-reproductible.fr/FR-RN/event/2023/01/11/Cancer-Biology.html"><![CDATA[<p>The lack of reproducibility in life sciences research, and particularly in Cancer Biology, is a growing concern in recent years, often referred to as ‘Reproducibility Crisis’. The Center for Open Science published in 2021, in the journal eLife, the results of its ‘Reproducibility Project: Cancer Biology’ reporting poor reproducibility of previously published results in the field of Cancer Research.</p>

<p><a href="https://oncospheremeeting.com/workshop-on-reproducibility-in-cancer-biology/">In this
workshop</a>
experts in different fields, through a transdisciplinary approach,
will discuss the causes, the implications and potential solutions for
the Reproducibility problems in Cancer Research.</p>

<p>More information at https://oncospheremeeting.com/workshop-on-reproducibility-in-cancer-biology/</p>]]></content><author><name>Recherche Reproductible</name></author><category term="event" /><summary type="html"><![CDATA[The lack of reproducibility in life sciences research, and particularly in Cancer Biology, is a growing concern in recent years, often referred to as ‘Reproducibility Crisis’. The Center for Open Science published in 2021, in the journal eLife, the results of its ‘Reproducibility Project: Cancer Biology’ reporting poor reproducibility of previously published results in the field of Cancer Research.]]></summary></entry><entry xml:lang="english"><title type="html">Benchopt: Reproducible, efficient and collaborative optimization benchmarks</title><link href="https://www.recherche-reproductible.fr/FR-RN/publication/2023/01/09/Benchopt.html" rel="alternate" type="text/html" title="Benchopt: Reproducible, efficient and collaborative optimization benchmarks" /><published>2023-01-09T07:00:00+00:00</published><updated>2023-01-09T07:00:00+00:00</updated><id>https://www.recherche-reproductible.fr/FR-RN/publication/2023/01/09/Benchopt</id><content type="html" xml:base="https://www.recherche-reproductible.fr/FR-RN/publication/2023/01/09/Benchopt.html"><![CDATA[<p>Numerical validation is at the core of machine learning research as it allows us to assess the actual impact of new methods, and to confirm the agreement between theory and practice. Yet, the rapid development of the field poses several challenges: researchers are confronted with a profusion of methods to compare, limited transparency and consensus on best practices, as well as tedious re-implementation work. As a result, validation is often very partial, which can lead to wrong conclusions that slow down the progress of research. We propose Benchopt, a collaborative framework to automatize, publish and reproduce optimization benchmarks in machine learning across programming languages and hardware architectures. Benchopt simplifies benchmarking for the community by providing an off-the-shelf tool for running, sharing and extending experiments. To demonstrate its broad usability, we showcase benchmarks on three standard ML tasks:
L2-regularized logistic regression, Lasso and ResNet18 training for image classification. These benchmarks highlight key practical findings that give a more nuanced view of state-of-the-art for these problems, showing that for practical evaluation, the devil is in the details.</p>

<p><a href="https://openreview.net/forum?id=1uSzacpyWLH"><span id="moreau2022benchopt"><span style="font-variant: small-caps">Moreau, T., Massias, M., Gramfort, A., et al.</span> 2022. Benchopt: Reproducible, efficient and collaborative optimization benchmarks. <i>NeuRIPS</i>.</span></a></p>]]></content><author><name>Recherche Reproductible</name></author><category term="publication" /><category term="computational" /><category term="science" /><summary type="html"><![CDATA[Numerical validation is at the core of machine learning research as it allows us to assess the actual impact of new methods, and to confirm the agreement between theory and practice. Yet, the rapid development of the field poses several challenges: researchers are confronted with a profusion of methods to compare, limited transparency and consensus on best practices, as well as tedious re-implementation work. As a result, validation is often very partial, which can lead to wrong conclusions that slow down the progress of research. We propose Benchopt, a collaborative framework to automatize, publish and reproduce optimization benchmarks in machine learning across programming languages and hardware architectures. Benchopt simplifies benchmarking for the community by providing an off-the-shelf tool for running, sharing and extending experiments. To demonstrate its broad usability, we showcase benchmarks on three standard ML tasks: L2-regularized logistic regression, Lasso and ResNet18 training for image classification. These benchmarks highlight key practical findings that give a more nuanced view of state-of-the-art for these problems, showing that for practical evaluation, the devil is in the details.]]></summary></entry><entry xml:lang="english"><title type="html">A Student’s Guide to Open Science: Using the Replication Crisis to Reform Psychology</title><link href="https://www.recherche-reproductible.fr/FR-RN/publication/2022/12/31/student-guide-open-science.html" rel="alternate" type="text/html" title="A Student’s Guide to Open Science: Using the Replication Crisis to Reform Psychology" /><published>2022-12-31T07:00:00+00:00</published><updated>2022-12-31T07:00:00+00:00</updated><id>https://www.recherche-reproductible.fr/FR-RN/publication/2022/12/31/student-guide-open-science</id><content type="html" xml:base="https://www.recherche-reproductible.fr/FR-RN/publication/2022/12/31/student-guide-open-science.html"><![CDATA[<p>A Student’s Guide to Open Science explores the so-called “replication crisis” in psychology (the inherent difficulties in reproducing research results to test the robustness of findings) while delving into the ways Open Science can address the crisis by transforming research practice.</p>

<p>Students will develop a fundamental understanding of the drivers and origins of the crisis and learn how Open Science practices can enhance research transparency, replication, and reproducibility.</p>

<p>With a handy, digestible guide for students and researchers alike on how to implement Open Science practices within their own workflow, as well as pedagogic teaching and learning activities that can be re-used by educators, Pennington’s new book is an essential guide to navigating the replication crisis.</p>

<p>Key features of this book include:</p>

<ul>
  <li>Case studies of classic psychological studies undergoing replication. </li>
  <li>Test yourself activities to reinforce learning of key concepts, including an open science crossword!</li>
  <li>Top tips boxes for open science practices including preregistration, Registered Reports, and open materials, code, and data. </li>
  <li>Useful illustrations to aid understanding and facilitate revision.</li>
</ul>

<p>New concepts and practices can often feel overwhelming, but this book aims to help students to pick what they want from the Open Science buffet and encourages them to keep returning to the table to fill up their plates again and again. Remember, we are all students of open science and will be for many years to come!</p>

<p>Charlotte Pennington is a Lecturer in Psychology at Aston University, UK and a Fellow of the Higher Education Academy. She is an expert in open science and advocates for the teaching of this within higher education pedagogy. </p>

<p><a href="https://www.amazon.co.uk/Students-Guide-Open-Science-Replication/dp/0335251161"><span id="Pennington2023"><span style="font-variant: small-caps">Pennington, C.</span> 2023. <i>A Student’s Guide to Open Science: Using the Replication Crisis to Reform Psychology</i>. Amazon.</span></a></p>]]></content><author><name>Recherche Reproductible</name></author><category term="publication" /><category term="psychology" /><summary type="html"><![CDATA[A Student’s Guide to Open Science explores the so-called “replication crisis” in psychology (the inherent difficulties in reproducing research results to test the robustness of findings) while delving into the ways Open Science can address the crisis by transforming research practice.]]></summary></entry><entry><title type="html">The Institute for Replication</title><link href="https://www.recherche-reproductible.fr/FR-RN/news/2022/12/12/replication-institute.html" rel="alternate" type="text/html" title="The Institute for Replication" /><published>2022-12-12T07:00:00+00:00</published><updated>2022-12-12T07:00:00+00:00</updated><id>https://www.recherche-reproductible.fr/FR-RN/news/2022/12/12/replication-institute</id><content type="html" xml:base="https://www.recherche-reproductible.fr/FR-RN/news/2022/12/12/replication-institute.html"><![CDATA[<p>The <a href="https://i4replication.org/">Institute for Replication (I4R)</a> works to improve the credibility of science by systematically reproducing and replicating research findings in leading academic journals. Our team collaborates with researchers to:</p>

<ul>
  <li><strong>Reproductions and Replications</strong>: Promote and generate reproductions and replications. Establish an open access website to serve as a central repository containing the replications, responses by the original authors and documentation.</li>
  <li><strong>Replication Resources</strong>: Prepare standardized file structure, code and documentation aimed at facilitating reproducibility and replicability by the broader community.</li>
  <li><strong>Teaching Resources</strong>: Develop and provide access to educational material on replication and open science.</li>
  <li><strong>Dissemination</strong>: Help researchers disseminate and publish reproductions and replications.</li>
</ul>]]></content><author><name>Recherche Reproductible</name></author><category term="news" /><summary type="html"><![CDATA[The Institute for Replication (I4R) works to improve the credibility of science by systematically reproducing and replicating research findings in leading academic journals. Our team collaborates with researchers to:]]></summary></entry><entry xml:lang="english"><title type="html">Toward practical transparent verifiable and long-term reproducible research using Guix</title><link href="https://www.recherche-reproductible.fr/FR-RN/publication/2022/12/12/GUIX.html" rel="alternate" type="text/html" title="Toward practical transparent verifiable and long-term reproducible research using Guix" /><published>2022-12-12T07:00:00+00:00</published><updated>2022-12-12T07:00:00+00:00</updated><id>https://www.recherche-reproductible.fr/FR-RN/publication/2022/12/12/GUIX</id><content type="html" xml:base="https://www.recherche-reproductible.fr/FR-RN/publication/2022/12/12/GUIX.html"><![CDATA[<p>Reproducibility crisis urge scientists to promote transparency which allows peers to draw same conclusions after performing identical steps from hypothesis to results. Growing resources are developed to open the access to methods, data and source codes. Still, the computational environment, an interface between data and source code running analyses, is not addressed. Environments are usually described with software and library names associated with version labels or provided as an opaque container image. This is not enough to describe the complexity of the dependencies on which they rely to operate on. We describe this issue and illustrate how open tools like Guix can be used by any scientist to share their environment and allow peers to reproduce it. Some steps of research might not be fully reproducible, but at least, transparency for computation is technically addressable. These tools should be considered by scientists willing to promote transparency and open science.</p>

<p><a href="https://www.nature.com/articles/s41597-022-01720-9"><span id="Vallet2022"><span style="font-variant: small-caps">Vallet, N., Michonneau, D., and Tournier, S.</span> 2022. Toward practical transparent verifiable and long-term reproducible research using Guix. <i>Scientific Data</i> <i>9</i>, 1.</span></a></p>]]></content><author><name>Recherche Reproductible</name></author><category term="publication" /><category term="computational" /><category term="science" /><summary type="html"><![CDATA[Reproducibility crisis urge scientists to promote transparency which allows peers to draw same conclusions after performing identical steps from hypothesis to results. Growing resources are developed to open the access to methods, data and source codes. Still, the computational environment, an interface between data and source code running analyses, is not addressed. Environments are usually described with software and library names associated with version labels or provided as an opaque container image. This is not enough to describe the complexity of the dependencies on which they rely to operate on. We describe this issue and illustrate how open tools like Guix can be used by any scientist to share their environment and allow peers to reproduce it. Some steps of research might not be fully reproducible, but at least, transparency for computation is technically addressable. These tools should be considered by scientists willing to promote transparency and open science.]]></summary></entry><entry><title type="html">Journée reproductibilité du LabEx Primes [fr]</title><link href="https://www.recherche-reproductible.fr/FR-RN/past-event/2022/12/08/journee-reproducibilite.html" rel="alternate" type="text/html" title="Journée reproductibilité du LabEx Primes [fr]" /><published>2022-12-08T07:00:00+00:00</published><updated>2022-12-08T07:00:00+00:00</updated><id>https://www.recherche-reproductible.fr/FR-RN/past-event/2022/12/08/journee-reproducibilite</id><content type="html" xml:base="https://www.recherche-reproductible.fr/FR-RN/past-event/2022/12/08/journee-reproducibilite.html"><![CDATA[<p>Le LabEx Primes organise une journée scientifique autour de la notion de
reproductibilité. Il s’agira d’aborder la reproductibilité d’un résultat
scientifique au sens large: reproductibilité expérimentale d’une mesure
(influence de la chaine d’acquisition, instrumentation, choix des paramètres),
reproductibilité numérique (chaine de traitement) dans le contexte de l’IA,
reproductibilité d’une simulation; ainsi que tout ce qui concerne l’analyse
statistique qui est mise œuvre, le questionnement sur les sources d’incertitude
et d’erreur. La journée est ouverte à toute personne intéressée. Plus d’information et inscription sur le site: https://reprod-primes.sciencesconf.org/</p>]]></content><author><name>Recherche Reproductible</name></author><category term="past-event" /><summary type="html"><![CDATA[Le LabEx Primes organise une journée scientifique autour de la notion de reproductibilité. Il s’agira d’aborder la reproductibilité d’un résultat scientifique au sens large: reproductibilité expérimentale d’une mesure (influence de la chaine d’acquisition, instrumentation, choix des paramètres), reproductibilité numérique (chaine de traitement) dans le contexte de l’IA, reproductibilité d’une simulation; ainsi que tout ce qui concerne l’analyse statistique qui est mise œuvre, le questionnement sur les sources d’incertitude et d’erreur. La journée est ouverte à toute personne intéressée. Plus d’information et inscription sur le site: https://reprod-primes.sciencesconf.org/]]></summary></entry><entry xml:lang="english"><title type="html">Sharing the Recipe: Reproducibility and Replicability in Research Across Disciplines</title><link href="https://www.recherche-reproductible.fr/FR-RN/publication/2022/11/20/sharing-recipe.html" rel="alternate" type="text/html" title="Sharing the Recipe: Reproducibility and Replicability in Research Across Disciplines" /><published>2022-11-20T07:00:00+00:00</published><updated>2022-11-20T07:00:00+00:00</updated><id>https://www.recherche-reproductible.fr/FR-RN/publication/2022/11/20/sharing-recipe</id><content type="html" xml:base="https://www.recherche-reproductible.fr/FR-RN/publication/2022/11/20/sharing-recipe.html"><![CDATA[<p>The open and transparent documentation of scientific processes has been established as a core antecedent of free knowledge. This also holds for generating robust insights in the scope of research projects. To convince academic peers and the public, the research process must be understandable and retraceable (reproducible), and repeatable (replicable) by others, precluding the inclusion of fluke findings into the canon of insights. In this contribution, we outline what reproducibility and replicability (R&amp;R) could mean in the scope of different disciplines and traditions of research and which significance R&amp;R has for generating insights in these fields. We draw on projects conducted in the scope of the Wikimedia “Open Science Fellows Program” (Fellowship Freies Wissen), an interdisciplinary, long-running funding scheme for projects contributing to open research practices. We identify twelve implemented projects from different disciplines which primarily focused on R&amp;R, and multiple additional projects also touching on R&amp;R. From these projects, we identify patterns and synthesize them into a roadmap of how research projects can achieve R&amp;R across different disciplines. We further outline the ground covered by these projects and propose ways forward.</p>

<p><a href="https://riojournal.com/article/89980/list/8/"><span id="Rahal2022"><span style="font-variant: small-caps">Rahal, R.-M., Hamann, H., Brohmer, H., and Pethig, F.</span> 2022. Sharing the Recipe: Reproducibility and Replicability in Research Across Disciplines. <i>Research Ideas and Outcomes</i> <i>8</i>.</span></a></p>]]></content><author><name>Recherche Reproductible</name></author><category term="publication" /><category term="science" /><summary type="html"><![CDATA[The open and transparent documentation of scientific processes has been established as a core antecedent of free knowledge. This also holds for generating robust insights in the scope of research projects. To convince academic peers and the public, the research process must be understandable and retraceable (reproducible), and repeatable (replicable) by others, precluding the inclusion of fluke findings into the canon of insights. In this contribution, we outline what reproducibility and replicability (R&amp;R) could mean in the scope of different disciplines and traditions of research and which significance R&amp;R has for generating insights in these fields. We draw on projects conducted in the scope of the Wikimedia “Open Science Fellows Program” (Fellowship Freies Wissen), an interdisciplinary, long-running funding scheme for projects contributing to open research practices. We identify twelve implemented projects from different disciplines which primarily focused on R&amp;R, and multiple additional projects also touching on R&amp;R. From these projects, we identify patterns and synthesize them into a roadmap of how research projects can achieve R&amp;R across different disciplines. We further outline the ground covered by these projects and propose ways forward.]]></summary></entry></feed>