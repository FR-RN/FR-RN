<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="https://www.recherche-reproductible.fr/FR-RN/feed.xml" rel="self" type="application/atom+xml" /><link href="https://www.recherche-reproductible.fr/FR-RN/" rel="alternate" type="text/html" /><updated>2022-07-11T07:53:25+00:00</updated><id>https://www.recherche-reproductible.fr/FR-RN/feed.xml</id><title type="html">Recherche Reproductible</title><subtitle>Un réseau national de chercheurs pour la promotion de la recherche reproductible.</subtitle><author><name>Recherche Reproductible</name></author><entry><title type="html">Science Europe Open Science Conference 2022 [en]</title><link href="https://www.recherche-reproductible.fr/FR-RN/event/2022/10/18/Open-Science-Conference.html" rel="alternate" type="text/html" title="Science Europe Open Science Conference 2022 [en]" /><published>2022-10-18T07:00:00+00:00</published><updated>2022-10-18T07:00:00+00:00</updated><id>https://www.recherche-reproductible.fr/FR-RN/event/2022/10/18/Open-Science-Conference</id><content type="html" xml:base="https://www.recherche-reproductible.fr/FR-RN/event/2022/10/18/Open-Science-Conference.html"><![CDATA[<p>Science Europe is organising its <a href="https://www.scienceeurope.org/events/open-science-conference-2022/">first conference on Open Science</a> at an important time: the COVID-19 pandemic has highlighted the value of open and collaborative research, and the November 2021 UNESCO Recommendation on Open Science has invited world regions to discuss shared values, principles, and standards.</p>

<p>At this 18 and 19 October Open Science conference, we will provide a comprehensive overview of the current policy initiatives, research assessment reforms, and financial measures that support the transition to Open Science, and look forward at new trends.</p>

<p>We will also explore the impact of the transition on the daily reality of researchers, their teams, and institutions, and discuss ways to make the transition to Open Science fair and equitable.</p>]]></content><author><name>Recherche Reproductible</name></author><category term="event" /><summary type="html"><![CDATA[Science Europe is organising its first conference on Open Science at an important time: the COVID-19 pandemic has highlighted the value of open and collaborative research, and the November 2021 UNESCO Recommendation on Open Science has invited world regions to discuss shared values, principles, and standards.]]></summary></entry><entry><title type="html">Reproducibility, Replicability and Trust in Science [en]</title><link href="https://www.recherche-reproductible.fr/FR-RN/event/2022/09/07/Reproducibility-Replicability-and-Trust.html" rel="alternate" type="text/html" title="Reproducibility, Replicability and Trust in Science [en]" /><published>2022-09-07T07:00:00+00:00</published><updated>2022-09-07T07:00:00+00:00</updated><id>https://www.recherche-reproductible.fr/FR-RN/event/2022/09/07/Reproducibility-Replicability-and-Trust</id><content type="html" xml:base="https://www.recherche-reproductible.fr/FR-RN/event/2022/09/07/Reproducibility-Replicability-and-Trust.html"><![CDATA[<p>This <a href="https://coursesandconferences.wellcomeconnectingscience.org/event/reproducibility-replicability-and-trust-in-science-20220907/">meeting</a> will bring together an international audience of researchers motivated to improve the robustness of scientific research. It will also include important stakeholder groups such as data and services providers, tool developers, publishers, institutions and funders that are developing policies relating to research reproducibility.</p>

<p>The overarching theme of the 2022 conference is to position the challenge of reproducibility and replicability as a behaviour-change problem that, when addressed, can lead to culture change within research. The various approaches to effecting and supporting this culture change will be explored in this year’s programme.</p>

<p>Discussions will include topics such as the challenges of ensuring reproducibility and replicability in large, multicentre research collaborations, training researchers in reproducibility, the role of policy development, tools that support reproducibility and replicability, social and behavioural aspects of culture change, local challenges to reproducibility on a global scale, and improving reproducibility and replicability leads to better-quality, transparent and more equitable research outputs, building.</p>

<p>The format will include presentations from international leaders with ample time for discussion and debate. Abstracts on all areas of the conference are welcome for a poster or oral presentation. The participation of early career researchers will be a strong and prominent thread throughout the conference.</p>

<p>In addition to the plenary presentations and discussion, the conference will include a panel discussion on how we could better demonstrate and measure progress in delivering more reproducible and replicable research, giving all delegates an opportunity to contribute.</p>]]></content><author><name>Recherche Reproductible</name></author><category term="event" /><summary type="html"><![CDATA[This meeting will bring together an international audience of researchers motivated to improve the robustness of scientific research. It will also include important stakeholder groups such as data and services providers, tool developers, publishers, institutions and funders that are developing policies relating to research reproducibility.]]></summary></entry><entry><title type="html">5th Oxford | Berlin Summer School on Open and Responsible Research in the Life Sciences 2022 [en]</title><link href="https://www.recherche-reproductible.fr/FR-RN/event/2022/09/05/Berlin-Summer-School.html" rel="alternate" type="text/html" title="5th Oxford | Berlin Summer School on Open and Responsible Research in the Life Sciences 2022 [en]" /><published>2022-09-05T07:00:00+00:00</published><updated>2022-09-05T07:00:00+00:00</updated><id>https://www.recherche-reproductible.fr/FR-RN/event/2022/09/05/Berlin-Summer-School</id><content type="html" xml:base="https://www.recherche-reproductible.fr/FR-RN/event/2022/09/05/Berlin-Summer-School.html"><![CDATA[<p>Transparency and reproducibility of research methods and results are important hallmarks of high quality in all areas, from biomedical to social and physical sciences. In the last few years, many novel approaches, tools, and technologies have emerged that allow for a comprehensive representation of the research process that goes far beyond descriptions of research methods and results as found in traditional journal articles. Open research practices have the potential to revolutionise the way research methods and results are communicated, and to facilitate research collaborations and sharing of research outputs in an unprecedented manner. However, adopting these practices requires knowledge and skills that are not normally taught in undergraduate or graduate degrees. To close this gap, we offer a <a href="https://www.bihealth.org/en/translation/innovation-enabler/quest-center/mission-approaches/education-and-training/oxford-berlin-summer-school-on-open-research">five-day summer school</a> to guide early career researchers (PhD students and postdocs) towards an open, transparent, and reproducible research workflow. These topics will be embedded in a more general curriculum on research ethics and meta-research. This year a special focus lies on ethics of animal experiments and the 3R principles (reduce, refine, replace). Dedicated workshops in this area will be offered and researchers from disciplines where animal research is relevant are particularly encouraged to apply.</p>]]></content><author><name>Recherche Reproductible</name></author><category term="event" /><summary type="html"><![CDATA[Transparency and reproducibility of research methods and results are important hallmarks of high quality in all areas, from biomedical to social and physical sciences. In the last few years, many novel approaches, tools, and technologies have emerged that allow for a comprehensive representation of the research process that goes far beyond descriptions of research methods and results as found in traditional journal articles. Open research practices have the potential to revolutionise the way research methods and results are communicated, and to facilitate research collaborations and sharing of research outputs in an unprecedented manner. However, adopting these practices requires knowledge and skills that are not normally taught in undergraduate or graduate degrees. To close this gap, we offer a five-day summer school to guide early career researchers (PhD students and postdocs) towards an open, transparent, and reproducible research workflow. These topics will be embedded in a more general curriculum on research ethics and meta-research. This year a special focus lies on ethics of animal experiments and the 3R principles (reduce, refine, replace). Dedicated workshops in this area will be offered and researchers from disciplines where animal research is relevant are particularly encouraged to apply.]]></summary></entry><entry xml:lang="english"><title type="html">Reproducibility of in-vivo electrophysiological measurements in mice</title><link href="https://www.recherche-reproductible.fr/FR-RN/publication/2022/05/09/reproducibility-in-vivo.html" rel="alternate" type="text/html" title="Reproducibility of in-vivo electrophysiological measurements in mice" /><published>2022-05-09T14:00:00+00:00</published><updated>2022-05-09T14:00:00+00:00</updated><id>https://www.recherche-reproductible.fr/FR-RN/publication/2022/05/09/reproducibility-in-vivo</id><content type="html" xml:base="https://www.recherche-reproductible.fr/FR-RN/publication/2022/05/09/reproducibility-in-vivo.html"><![CDATA[<p>Understanding whole-brain-scale electrophysiological recordings will rely on the collective work of multiple labs. Because two labs recording from the same brain area often reach different conclusions, it is critical to quantify and control for features that decrease reproducibility. To address these issues, we formed a multi-lab collaboration using a shared, open-source behavioral task and experimental apparatus. We repeatedly inserted Neuropixels multi-electrode probes targeting the same brain locations (including posterior parietal cortex, hippocampus, and thalamus) in mice performing the behavioral task. We gathered data across 9 labs and developed a common histological and data processing pipeline to analyze the resulting large datasets. After applying stringent behavioral, histological, and electrophysiological quality-control criteria, we found that neuronal yield, firing rates, spike amplitudes, and task-modulated neuronal activity were reproducible across laboratories. To quantify variance in neural activity explained by task variables (e.g., stimulus onset time), behavioral variables (timing of licks/paw movements), and other variables (e.g., spatial location in the brain or the lab ID), we developed a multi-task neural network encoding model that extends common, simpler regression approaches by allowing nonlinear interactions between variables. We found that within-lab random effects captured by this model were comparable to between-lab random effects. Taken together, these results demonstrate that across-lab standardization of electrophysiological procedures can lead to reproducible results across labs. Moreover, our protocols to achieve reproducibility, along with our analyses to evaluate it are openly accessible to the scientific community, along with our extensive electrophysiological dataset with corresponding behavior and open-source analysis code.</p>

<p><a href="https://www.biorxiv.org/content/10.1101/2022.05.09.491042v1"><span id="IBL:2022"><span style="font-variant: small-caps">Laboratory, I.B., Banga, K., Benson, J., et al.</span> 2022. Reproducibility of in-vivo electrophysiological measurements in mice. <i>bioRxiv</i>.</span></a></p>]]></content><author><name>Recherche Reproductible</name></author><category term="publication" /><category term="neuroscience" /><summary type="html"><![CDATA[Understanding whole-brain-scale electrophysiological recordings will rely on the collective work of multiple labs. Because two labs recording from the same brain area often reach different conclusions, it is critical to quantify and control for features that decrease reproducibility. To address these issues, we formed a multi-lab collaboration using a shared, open-source behavioral task and experimental apparatus. We repeatedly inserted Neuropixels multi-electrode probes targeting the same brain locations (including posterior parietal cortex, hippocampus, and thalamus) in mice performing the behavioral task. We gathered data across 9 labs and developed a common histological and data processing pipeline to analyze the resulting large datasets. After applying stringent behavioral, histological, and electrophysiological quality-control criteria, we found that neuronal yield, firing rates, spike amplitudes, and task-modulated neuronal activity were reproducible across laboratories. To quantify variance in neural activity explained by task variables (e.g., stimulus onset time), behavioral variables (timing of licks/paw movements), and other variables (e.g., spatial location in the brain or the lab ID), we developed a multi-task neural network encoding model that extends common, simpler regression approaches by allowing nonlinear interactions between variables. We found that within-lab random effects captured by this model were comparable to between-lab random effects. Taken together, these results demonstrate that across-lab standardization of electrophysiological procedures can lead to reproducible results across labs. Moreover, our protocols to achieve reproducibility, along with our analyses to evaluate it are openly accessible to the scientific community, along with our extensive electrophysiological dataset with corresponding behavior and open-source analysis code.]]></summary></entry><entry xml:lang="english"><title type="html">Share the code, not just the data: A case study of the reproducibility of articles published in the Journal of Memory and Language under the open data policy</title><link href="https://www.recherche-reproductible.fr/FR-RN/publication/2022/04/18/share-the-code.html" rel="alternate" type="text/html" title="Share the code, not just the data: A case study of the reproducibility of articles published in the Journal of Memory and Language under the open data policy" /><published>2022-04-18T14:00:00+00:00</published><updated>2022-04-18T14:00:00+00:00</updated><id>https://www.recherche-reproductible.fr/FR-RN/publication/2022/04/18/share-the-code</id><content type="html" xml:base="https://www.recherche-reproductible.fr/FR-RN/publication/2022/04/18/share-the-code.html"><![CDATA[<p>In 2019 the Journal of Memory and Language instituted an open data and code policy; this policy requires that, as a rule, code and data be released at the latest upon publication. How effective is this policy? We compared 59 papers published before, and 59 papers published after, the policy took effect. After the policy was in place, the rate of data sharing increased by more than 50%. We further looked at whether papers published under the open data policy were reproducible, in the sense that the published results should be possible to regenerate given the data, and given the code, when code was provided. For 8 out of the 59 papers, data sets were inaccessible. The reproducibility rate ranged from 34% to 56%, depending on the reproducibility criteria. The strongest predictor of whether an attempt to reproduce would be successful is the presence of the analysis code: it increases the probability of reproducing reported results by almost 40%. We propose two simple steps that can increase the reproducibility of published papers: share the analysis code, and attempt to reproduce one’s own analysis using only the shared materials.</p>

<p><a href="https://psyarxiv.com/hf297/"><span id="Laurinavichyute:2022"><span style="font-variant: small-caps">Laurinavichyute, A., Yadav, H., and Vasishth, S.</span> 2021. Share the code,  not just the data: A case study of the reproducibility of articles published in the Journal of Memory and Language under the open data policy. .</span></a></p>]]></content><author><name>Recherche Reproductible</name></author><category term="publication" /><category term="cognitive" /><category term="science" /><summary type="html"><![CDATA[In 2019 the Journal of Memory and Language instituted an open data and code policy; this policy requires that, as a rule, code and data be released at the latest upon publication. How effective is this policy? We compared 59 papers published before, and 59 papers published after, the policy took effect. After the policy was in place, the rate of data sharing increased by more than 50%. We further looked at whether papers published under the open data policy were reproducible, in the sense that the published results should be possible to regenerate given the data, and given the code, when code was provided. For 8 out of the 59 papers, data sets were inaccessible. The reproducibility rate ranged from 34% to 56%, depending on the reproducibility criteria. The strongest predictor of whether an attempt to reproduce would be successful is the presence of the analysis code: it increases the probability of reproducing reported results by almost 40%. We propose two simple steps that can increase the reproducibility of published papers: share the analysis code, and attempt to reproduce one’s own analysis using only the shared materials.]]></summary></entry><entry xml:lang="english"><title type="html">Methodology over metrics: current scientific standards are a disservice to patients and society</title><link href="https://www.recherche-reproductible.fr/FR-RN/publication/2022/04/17/Methodology-over-metrics.html" rel="alternate" type="text/html" title="Methodology over metrics: current scientific standards are a disservice to patients and society" /><published>2022-04-17T14:00:00+00:00</published><updated>2022-04-17T14:00:00+00:00</updated><id>https://www.recherche-reproductible.fr/FR-RN/publication/2022/04/17/Methodology-over-metrics</id><content type="html" xml:base="https://www.recherche-reproductible.fr/FR-RN/publication/2022/04/17/Methodology-over-metrics.html"><![CDATA[<p>Covid-19 research made it painfully clear that the scandal of poor medical research, as denounced by Altman in 1994, persists today. The overall quality of medical research remains poor, despite longstanding criticisms. The problems are well known, but the research community fails to properly address them. We suggest that most problems stem from an underlying paradox: although methodology is undeniably the backbone of high-quality and responsible research, science consistently undervalues methodology. The focus remains more on the destination (research claims and metrics) than on the journey. Notwithstanding, research should serve society more than the reputation of those involved. While we notice that many initiatives are being established to improve components of the research cycle, these initiatives are too disjointed. The overall system is monolithic and slow to adapt. We assert that top-down action is needed from journals, universities, funders and governments to break the cycle and put methodology first. These actions should involve the widespread adoption of registered reports, balanced research funding between innovative, incremental and methodological research projects, full recognition and demystification of peer review, improved methodological review of reports, adherence to reporting guidelines, and investment in methodological education and research. Currently, the scientific enterprise is doing a major disservice to patients and society.</p>

<p><a href="https://www.jclinepi.com/article/S0895-4356(21)00170-0/fulltext"><span id="VanCalster:2021"><span style="font-variant: small-caps">Van Calster, B., Wynants, L., Riley, R.D., Smeden, M. van, and Collins, G.S.</span> 2021. Methodology over metrics: current scientific
                  standards are a disservice to patients and society. <i>Journal of Clinical Epidemiology</i> <i>138</i>, 219–226.</span></a></p>]]></content><author><name>Recherche Reproductible</name></author><category term="publication" /><category term="medicine" /><summary type="html"><![CDATA[Covid-19 research made it painfully clear that the scandal of poor medical research, as denounced by Altman in 1994, persists today. The overall quality of medical research remains poor, despite longstanding criticisms. The problems are well known, but the research community fails to properly address them. We suggest that most problems stem from an underlying paradox: although methodology is undeniably the backbone of high-quality and responsible research, science consistently undervalues methodology. The focus remains more on the destination (research claims and metrics) than on the journey. Notwithstanding, research should serve society more than the reputation of those involved. While we notice that many initiatives are being established to improve components of the research cycle, these initiatives are too disjointed. The overall system is monolithic and slow to adapt. We assert that top-down action is needed from journals, universities, funders and governments to break the cycle and put methodology first. These actions should involve the widespread adoption of registered reports, balanced research funding between innovative, incremental and methodological research projects, full recognition and demystification of peer review, improved methodological review of reports, adherence to reporting guidelines, and investment in methodological education and research. Currently, the scientific enterprise is doing a major disservice to patients and society.]]></summary></entry><entry xml:lang="english"><title type="html">Overcoming the Reproducibility Crisis - Results of the first Community Survey of the German National Research Data Infrastructure for Neuroscience</title><link href="https://www.recherche-reproductible.fr/FR-RN/publication/2022/04/11/Overcoming-reproducibility-crisis.html" rel="alternate" type="text/html" title="Overcoming the Reproducibility Crisis - Results of the first Community Survey of the German National Research Data Infrastructure for Neuroscience" /><published>2022-04-11T14:00:00+00:00</published><updated>2022-04-11T14:00:00+00:00</updated><id>https://www.recherche-reproductible.fr/FR-RN/publication/2022/04/11/Overcoming-reproducibility-crisis</id><content type="html" xml:base="https://www.recherche-reproductible.fr/FR-RN/publication/2022/04/11/Overcoming-reproducibility-crisis.html"><![CDATA[<p>The lack of reproducibility of research results is a serious problem - known as “the reproducibility crisis”. The German National Research Data Infrastructure (NFDI) initiative implemented by the German Research Foundation (DFG) aims to help overcoming this crisis by developing sustainable solutions for research data management (RDM). NFDI comprises domain specific consortia across all science disciplines. In the field of neuroscience, NFDI Neuroscience (NFDI-Neuro) contributes to the strengthening of systematic and standardized RDM in its research communities. NFDI-Neuro conducted a comprehensive survey amongst the neuroscience community to determine the current needs, challenges, and opinions with respect to RDM. The outcomes of this survey are presented here. The German neuroscience community perceives barriers with respect to RDM and data sharing mainly linked to (1) lack of data and metadata standards, (2) lack of community adopted provenance tracking methods, 3) lack of a privacy preserving research infrastructure for sensitive data (4) lack of RDM literacy and (5) lack of required time and resources for proper RDM. NFDI-Neuro aims to systematically address these barriers by leading and contributing to the development of standards, tools, and infrastructure and by providing training, education and support, as well as additional resources to its research community. The RDM work of NFDI-Neuro is conducted in close collaboration with its partner EBRAINS AISBL, the coordinating entity of the EU Flagship Human Brain Project, and its Research Infrastructure (RI) EBRAINS with more than 4500 registered users and developers from more than 30 countries. While NFDI-Neuro aims to address the national needs, it closely aligns with the international community and the topics of the Digital Europe Program and EU Data Spaces.</p>

<p><a href="https://www.biorxiv.org/content/10.1101/2022.04.07.487439v1"><span id="Klingner:2022"><span style="font-variant: small-caps">Klingner, C.M., Denker, M., Grün, S., et al.</span> 2022. Overcoming the Reproducibility Crisis - Results of
                  the first Community Survey of the German National
                  Research Data Infrastructure for Neuroscience. .</span></a></p>]]></content><author><name>Recherche Reproductible</name></author><category term="publication" /><category term="neuroscience" /><summary type="html"><![CDATA[The lack of reproducibility of research results is a serious problem - known as “the reproducibility crisis”. The German National Research Data Infrastructure (NFDI) initiative implemented by the German Research Foundation (DFG) aims to help overcoming this crisis by developing sustainable solutions for research data management (RDM). NFDI comprises domain specific consortia across all science disciplines. In the field of neuroscience, NFDI Neuroscience (NFDI-Neuro) contributes to the strengthening of systematic and standardized RDM in its research communities. NFDI-Neuro conducted a comprehensive survey amongst the neuroscience community to determine the current needs, challenges, and opinions with respect to RDM. The outcomes of this survey are presented here. The German neuroscience community perceives barriers with respect to RDM and data sharing mainly linked to (1) lack of data and metadata standards, (2) lack of community adopted provenance tracking methods, 3) lack of a privacy preserving research infrastructure for sensitive data (4) lack of RDM literacy and (5) lack of required time and resources for proper RDM. NFDI-Neuro aims to systematically address these barriers by leading and contributing to the development of standards, tools, and infrastructure and by providing training, education and support, as well as additional resources to its research community. The RDM work of NFDI-Neuro is conducted in close collaboration with its partner EBRAINS AISBL, the coordinating entity of the EU Flagship Human Brain Project, and its Research Infrastructure (RI) EBRAINS with more than 4500 registered users and developers from more than 30 countries. While NFDI-Neuro aims to address the national needs, it closely aligns with the international community and the topics of the Digital Europe Program and EU Data Spaces.]]></summary></entry><entry><title type="html">MOOC Science ouverte</title><link href="https://www.recherche-reproductible.fr/FR-RN/past-event/2022/03/18/MOOC-Open-Science.html" rel="alternate" type="text/html" title="MOOC Science ouverte" /><published>2022-03-18T07:00:00+00:00</published><updated>2022-03-18T07:00:00+00:00</updated><id>https://www.recherche-reproductible.fr/FR-RN/past-event/2022/03/18/MOOC-Open-Science</id><content type="html" xml:base="https://www.recherche-reproductible.fr/FR-RN/past-event/2022/03/18/MOOC-Open-Science.html"><![CDATA[<p>Un <strong><a href="https://www.mnhn.fr/fr/actualites/mooc-science-ouverte">cours en ligne
gratuit</a></strong>
pour tout savoir sur le concept de science ouverte : inscription
jusqu’au 18 mars 2022.</p>

<p>Aussi appelée “open science” ou “open research”, la science ouverte vise à construire un écosystème dans lequel la science sera plus cumulative, plus fortement étayée par des données en considérant la science et les données comme un « bien commun ». Vous allez découvrir l’évolution et les transformations des pratiques de recherche, de la production des savoirs scientifiques jusqu’à leur diffusion.</p>

<p>Ce MOOC a été conçu dans le cadre de l’Alliance Sorbonne Université, par une équipe mixte issue des bibliothèques de Sorbonne Université et du Muséum. Celui-ci va permettre de former doctorants et tout public aux enjeux et pratiques de la science ouverte.</p>

<p>Le cours est accessible du 7 mars 2022 au 1er avril 2022.
Effort estimé : 2 h par semaine, réparties sur 4 semaines.</p>]]></content><author><name>Recherche Reproductible</name></author><category term="past-event" /><summary type="html"><![CDATA[Un cours en ligne gratuit pour tout savoir sur le concept de science ouverte : inscription jusqu’au 18 mars 2022.]]></summary></entry><entry><title type="html">Meeting GT Notebook</title><link href="https://www.recherche-reproductible.fr/FR-RN/past-event/2022/03/10/GT-Notebook-March-Meeting.html" rel="alternate" type="text/html" title="Meeting GT Notebook" /><published>2022-03-10T09:00:00+00:00</published><updated>2022-03-10T09:00:00+00:00</updated><id>https://www.recherche-reproductible.fr/FR-RN/past-event/2022/03/10/GT-Notebook-March-Meeting</id><content type="html" xml:base="https://www.recherche-reproductible.fr/FR-RN/past-event/2022/03/10/GT-Notebook-March-Meeting.html"><![CDATA[<p>Qu’on les appelle “notebooks”, “article exécutable” ou “publication reproductible”, la démocratisation du <em>Literate Programming</em> et des technologies supports (Org; RMarkdown ; Jupyter) soulève un ensemble de problématiques susceptible d’interroger de nombreux métiers de l’enseignement supérieur et de la recherche.</p>

<p>L’objet questionne non seulement nos pratiques scientifiques (reproductibilité, écriture scientifique, etc.) mais également les chaînes de publications; les infrastructures matérielles et logicielles susceptibles d’accueillir ces pratiques, tout comme leur appropriation et la médiation entre équipes de recherche, étudiants et étudiantes et personnel d’appui à la recherche.</p>

<p>Le premier objectif de ce <strong>GT inter-disciplinaire</strong> était de mettre en oeuvre <a href="https://jedata-normande.sciencesconf.org/resource/page/id/4">un premier atelier</a> de sensibilisation sur ces questions dans le cadre des <a href="https://jedata-normande.sciencesconf.org/">journées</a> <em>“Cycle de vie des données de la recherche”</em>. Les <a href="https://gitlab.huma-num.fr/gt-notebook/workshop/workshop_3_decembre_2021/slide">supports</a>, les <a href="https://gitlab.huma-num.fr/gt-notebook/workshop/workshop_3_decembre_2021/slide2html-3-dec">commentaires</a> et <a href="https://gitlab.huma-num.fr/gt-notebook/workshop/workshop_3_decembre_2021/atelier_notebooks">Notebooks</a> utilisé pour la formation sont reproductibles, disponibles en ligne.</p>

<p>Déjà composée d’une vingtaine de membres, venant de toutes disciplines, le GT et la mailling-liste sont ouverts à tous⋅tes personnes et toutes disciplines intéressé⋅e⋅s par ces questions.</p>

<p>A ce titre, vous êtes également le⋅a bienvenu⋅e à la prochaine réunion du GT,  entre autres pour discuter des projets à venir, celle-ci est prévu <strong>le 10 mars entre 10h et 12h</strong> : <a href="https://webconf.univ-rouen.fr/greenlight/rey-px2-ewg-7av">lien de visio</a></p>]]></content><author><name>Recherche Reproductible</name></author><category term="past-event" /><summary type="html"><![CDATA[Qu’on les appelle “notebooks”, “article exécutable” ou “publication reproductible”, la démocratisation du Literate Programming et des technologies supports (Org; RMarkdown ; Jupyter) soulève un ensemble de problématiques susceptible d’interroger de nombreux métiers de l’enseignement supérieur et de la recherche.]]></summary></entry><entry xml:lang="english"><title type="html">A large-scale study on research code quality and execution</title><link href="https://www.recherche-reproductible.fr/FR-RN/publication/2022/02/21/large-scale-study.html" rel="alternate" type="text/html" title="A large-scale study on research code quality and execution" /><published>2022-02-21T17:00:00+00:00</published><updated>2022-02-21T17:00:00+00:00</updated><id>https://www.recherche-reproductible.fr/FR-RN/publication/2022/02/21/large-scale-study</id><content type="html" xml:base="https://www.recherche-reproductible.fr/FR-RN/publication/2022/02/21/large-scale-study.html"><![CDATA[<p>This article presents a study on the quality and execution of research code from publicly-available replication datasets at the Harvard Dataverse repository. Research code is typically created by a group of scientists and published together with academic papers to facilitate research transparency and reproducibility. For this study, we define ten questions to address aspects impacting research reproducibility and reuse. First, we retrieve and analyze more than 2000 replication datasets with over 9000 unique R files published from 2010 to 2020. Second, we execute the code in a clean runtime environment to assess its ease of reuse. Common coding errors were identified, and some of them were solved with automatic code cleaning to aid code execution. We find that 74% of R files failed to complete without error in the initial execution, while 56% failed when code cleaning was applied, showing that many errors can be prevented with good coding practices. We also analyze the replication datasets from journals’ collections and discuss the impact of the journal policy strictness on the code re-execution rate. Finally, based on our results, we propose a set of recommendations for code dissemination aimed at researchers, journals, and repositories.</p>

<p><a href="https://www.nature.com/articles/s41597-022-01143-6"><span id="Trisovic2022"><span style="font-variant: small-caps">Trisovic, A., Lau, M.K., Pasquier, T., and Crosas, M.</span> 2022. A large-scale study on research code quality and
                  execution. <i>Scientific Data</i> <i>9</i>, 1.</span></a></p>]]></content><author><name>Recherche Reproductible</name></author><category term="publication" /><category term="computer" /><category term="science" /><summary type="html"><![CDATA[This article presents a study on the quality and execution of research code from publicly-available replication datasets at the Harvard Dataverse repository. Research code is typically created by a group of scientists and published together with academic papers to facilitate research transparency and reproducibility. For this study, we define ten questions to address aspects impacting research reproducibility and reuse. First, we retrieve and analyze more than 2000 replication datasets with over 9000 unique R files published from 2010 to 2020. Second, we execute the code in a clean runtime environment to assess its ease of reuse. Common coding errors were identified, and some of them were solved with automatic code cleaning to aid code execution. We find that 74% of R files failed to complete without error in the initial execution, while 56% failed when code cleaning was applied, showing that many errors can be prevented with good coding practices. We also analyze the replication datasets from journals’ collections and discuss the impact of the journal policy strictness on the code re-execution rate. Finally, based on our results, we propose a set of recommendations for code dissemination aimed at researchers, journals, and repositories.]]></summary></entry></feed>