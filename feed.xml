<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="https://www.recherche-reproductible.fr/FR-RN/feed.xml" rel="self" type="application/atom+xml" /><link href="https://www.recherche-reproductible.fr/FR-RN/" rel="alternate" type="text/html" /><updated>2022-10-11T12:11:11+00:00</updated><id>https://www.recherche-reproductible.fr/FR-RN/feed.xml</id><title type="html">Recherche Reproductible</title><subtitle>Un réseau national de chercheurs pour la promotion de la recherche reproductible.</subtitle><author><name>Recherche Reproductible</name></author><entry><title type="html">Journée reproductibilité du LabEx Primes [fr]</title><link href="https://www.recherche-reproductible.fr/FR-RN/event/2022/12/08/journee-reproducibilite.html" rel="alternate" type="text/html" title="Journée reproductibilité du LabEx Primes [fr]" /><published>2022-12-08T07:00:00+00:00</published><updated>2022-12-08T07:00:00+00:00</updated><id>https://www.recherche-reproductible.fr/FR-RN/event/2022/12/08/journee-reproducibilite</id><content type="html" xml:base="https://www.recherche-reproductible.fr/FR-RN/event/2022/12/08/journee-reproducibilite.html"><![CDATA[<p>Le LabEx Primes organise une journée scientifique autour de la notion de
reproductibilité. Il s’agira d’aborder la reproductibilité d’un résultat
scientifique au sens large: reproductibilité expérimentale d’une mesure
(influence de la chaine d’acquisition, instrumentation, choix des paramètres),
reproductibilité numérique (chaine de traitement) dans le contexte de l’IA,
reproductibilité d’une simulation; ainsi que tout ce qui concerne l’analyse
statistique qui est mise œuvre, le questionnement sur les sources d’incertitude
et d’erreur. La journée est ouverte à toute personne intéressée. Plus d’information et inscription sur le site: https://reprod-primes.sciencesconf.org/</p>]]></content><author><name>Recherche Reproductible</name></author><category term="event" /><summary type="html"><![CDATA[Le LabEx Primes organise une journée scientifique autour de la notion de reproductibilité. Il s’agira d’aborder la reproductibilité d’un résultat scientifique au sens large: reproductibilité expérimentale d’une mesure (influence de la chaine d’acquisition, instrumentation, choix des paramètres), reproductibilité numérique (chaine de traitement) dans le contexte de l’IA, reproductibilité d’une simulation; ainsi que tout ce qui concerne l’analyse statistique qui est mise œuvre, le questionnement sur les sources d’incertitude et d’erreur. La journée est ouverte à toute personne intéressée. Plus d’information et inscription sur le site: https://reprod-primes.sciencesconf.org/]]></summary></entry><entry><title type="html">Science Europe Open Science Conference 2022 [en]</title><link href="https://www.recherche-reproductible.fr/FR-RN/event/2022/10/18/Open-Science-Conference.html" rel="alternate" type="text/html" title="Science Europe Open Science Conference 2022 [en]" /><published>2022-10-18T07:00:00+00:00</published><updated>2022-10-18T07:00:00+00:00</updated><id>https://www.recherche-reproductible.fr/FR-RN/event/2022/10/18/Open-Science-Conference</id><content type="html" xml:base="https://www.recherche-reproductible.fr/FR-RN/event/2022/10/18/Open-Science-Conference.html"><![CDATA[<p>Science Europe is organising its <a href="https://www.scienceeurope.org/events/open-science-conference-2022/">first conference on Open Science</a> at an important time: the COVID-19 pandemic has highlighted the value of open and collaborative research, and the November 2021 UNESCO Recommendation on Open Science has invited world regions to discuss shared values, principles, and standards.</p>

<p>At this 18 and 19 October Open Science conference, we will provide a comprehensive overview of the current policy initiatives, research assessment reforms, and financial measures that support the transition to Open Science, and look forward at new trends.</p>

<p>We will also explore the impact of the transition on the daily reality of researchers, their teams, and institutions, and discuss ways to make the transition to Open Science fair and equitable.</p>]]></content><author><name>Recherche Reproductible</name></author><category term="event" /><summary type="html"><![CDATA[Science Europe is organising its first conference on Open Science at an important time: the COVID-19 pandemic has highlighted the value of open and collaborative research, and the November 2021 UNESCO Recommendation on Open Science has invited world regions to discuss shared values, principles, and standards.]]></summary></entry><entry xml:lang="french"><title type="html">Intégrer les Réplications dans les Programmes de Licence : Bénéfices pour l’Enseignement, la Science, et la Société</title><link href="https://www.recherche-reproductible.fr/FR-RN/publication/2022/10/06/Teaching-Replication.html" rel="alternate" type="text/html" title="Intégrer les Réplications dans les Programmes de Licence : Bénéfices pour l’Enseignement, la Science, et la Société" /><published>2022-10-06T07:00:00+00:00</published><updated>2022-10-06T07:00:00+00:00</updated><id>https://www.recherche-reproductible.fr/FR-RN/publication/2022/10/06/Teaching-Replication</id><content type="html" xml:base="https://www.recherche-reproductible.fr/FR-RN/publication/2022/10/06/Teaching-Replication.html"><![CDATA[<p>Depuis plus d’une décennie, la recherche en psychologie a du mal à reproduire de nombreuses études bien connues et très citées. Cette crise de la réplication a été à l’origine de l’émergence de plusieurs projets scientifiques “Big Team”. L’un des premiers contributeurs au mouvement Big-Team Science est le Collaborative Replication and Education Project (CREP), un projet de collaboration à grande échelle par lequel des étudiants de premier cycle universitaire peuvent contribuer aux connaissances scientifiques par le biais d’études de réplication. Non seulement le CREP permet aux étudiants d’apprendre et de s’intéresser aux méthodes de recherche indépendamment de la nouveauté de leur étude, mais il offre également une contribution incroyable à la communauté des chercheurs dans son ensemble.</p>

<p><a href="https://psyarxiv.com/8dhbg/"><span id="Ribotta2022"><span style="font-variant: small-caps">Ribotta, B., Bellemin, R., Grahe, J.E., IJzerman, H., Wagge, J.R., and Mailliez, M.</span> 2022. Intégrer les Réplications dans les Programmes de Licence : Bénéfices pour l’Enseignement,  la Science,  et la Société. .</span></a></p>]]></content><author><name>Recherche Reproductible</name></author><category term="publication" /><category term="psychology" /><summary type="html"><![CDATA[Depuis plus d’une décennie, la recherche en psychologie a du mal à reproduire de nombreuses études bien connues et très citées. Cette crise de la réplication a été à l’origine de l’émergence de plusieurs projets scientifiques “Big Team”. L’un des premiers contributeurs au mouvement Big-Team Science est le Collaborative Replication and Education Project (CREP), un projet de collaboration à grande échelle par lequel des étudiants de premier cycle universitaire peuvent contribuer aux connaissances scientifiques par le biais d’études de réplication. Non seulement le CREP permet aux étudiants d’apprendre et de s’intéresser aux méthodes de recherche indépendamment de la nouveauté de leur étude, mais il offre également une contribution incroyable à la communauté des chercheurs dans son ensemble.]]></summary></entry><entry><title type="html">Reproducibility, Replicability and Trust in Science [en]</title><link href="https://www.recherche-reproductible.fr/FR-RN/past-event/2022/09/07/Reproducibility-Replicability-and-Trust.html" rel="alternate" type="text/html" title="Reproducibility, Replicability and Trust in Science [en]" /><published>2022-09-07T07:00:00+00:00</published><updated>2022-09-07T07:00:00+00:00</updated><id>https://www.recherche-reproductible.fr/FR-RN/past-event/2022/09/07/Reproducibility-Replicability-and-Trust</id><content type="html" xml:base="https://www.recherche-reproductible.fr/FR-RN/past-event/2022/09/07/Reproducibility-Replicability-and-Trust.html"><![CDATA[<p>This <a href="https://coursesandconferences.wellcomeconnectingscience.org/event/reproducibility-replicability-and-trust-in-science-20220907/">meeting</a> will bring together an international audience of researchers motivated to improve the robustness of scientific research. It will also include important stakeholder groups such as data and services providers, tool developers, publishers, institutions and funders that are developing policies relating to research reproducibility.</p>

<p>The overarching theme of the 2022 conference is to position the challenge of reproducibility and replicability as a behaviour-change problem that, when addressed, can lead to culture change within research. The various approaches to effecting and supporting this culture change will be explored in this year’s programme.</p>

<p>Discussions will include topics such as the challenges of ensuring reproducibility and replicability in large, multicentre research collaborations, training researchers in reproducibility, the role of policy development, tools that support reproducibility and replicability, social and behavioural aspects of culture change, local challenges to reproducibility on a global scale, and improving reproducibility and replicability leads to better-quality, transparent and more equitable research outputs, building.</p>

<p>The format will include presentations from international leaders with ample time for discussion and debate. Abstracts on all areas of the conference are welcome for a poster or oral presentation. The participation of early career researchers will be a strong and prominent thread throughout the conference.</p>

<p>In addition to the plenary presentations and discussion, the conference will include a panel discussion on how we could better demonstrate and measure progress in delivering more reproducible and replicable research, giving all delegates an opportunity to contribute.</p>]]></content><author><name>Recherche Reproductible</name></author><category term="past-event" /><summary type="html"><![CDATA[This meeting will bring together an international audience of researchers motivated to improve the robustness of scientific research. It will also include important stakeholder groups such as data and services providers, tool developers, publishers, institutions and funders that are developing policies relating to research reproducibility.]]></summary></entry><entry><title type="html">5th Oxford | Berlin Summer School on Open and Responsible Research in the Life Sciences 2022 [en]</title><link href="https://www.recherche-reproductible.fr/FR-RN/past-event/2022/09/05/Berlin-Summer-School.html" rel="alternate" type="text/html" title="5th Oxford | Berlin Summer School on Open and Responsible Research in the Life Sciences 2022 [en]" /><published>2022-09-05T07:00:00+00:00</published><updated>2022-09-05T07:00:00+00:00</updated><id>https://www.recherche-reproductible.fr/FR-RN/past-event/2022/09/05/Berlin-Summer-School</id><content type="html" xml:base="https://www.recherche-reproductible.fr/FR-RN/past-event/2022/09/05/Berlin-Summer-School.html"><![CDATA[<p>Transparency and reproducibility of research methods and results are important hallmarks of high quality in all areas, from biomedical to social and physical sciences. In the last few years, many novel approaches, tools, and technologies have emerged that allow for a comprehensive representation of the research process that goes far beyond descriptions of research methods and results as found in traditional journal articles. Open research practices have the potential to revolutionise the way research methods and results are communicated, and to facilitate research collaborations and sharing of research outputs in an unprecedented manner. However, adopting these practices requires knowledge and skills that are not normally taught in undergraduate or graduate degrees. To close this gap, we offer a <a href="https://www.bihealth.org/en/translation/innovation-enabler/quest-center/mission-approaches/education-and-training/oxford-berlin-summer-school-on-open-research">five-day summer school</a> to guide early career researchers (PhD students and postdocs) towards an open, transparent, and reproducible research workflow. These topics will be embedded in a more general curriculum on research ethics and meta-research. This year a special focus lies on ethics of animal experiments and the 3R principles (reduce, refine, replace). Dedicated workshops in this area will be offered and researchers from disciplines where animal research is relevant are particularly encouraged to apply.</p>]]></content><author><name>Recherche Reproductible</name></author><category term="past-event" /><summary type="html"><![CDATA[Transparency and reproducibility of research methods and results are important hallmarks of high quality in all areas, from biomedical to social and physical sciences. In the last few years, many novel approaches, tools, and technologies have emerged that allow for a comprehensive representation of the research process that goes far beyond descriptions of research methods and results as found in traditional journal articles. Open research practices have the potential to revolutionise the way research methods and results are communicated, and to facilitate research collaborations and sharing of research outputs in an unprecedented manner. However, adopting these practices requires knowledge and skills that are not normally taught in undergraduate or graduate degrees. To close this gap, we offer a five-day summer school to guide early career researchers (PhD students and postdocs) towards an open, transparent, and reproducible research workflow. These topics will be embedded in a more general curriculum on research ethics and meta-research. This year a special focus lies on ethics of animal experiments and the 3R principles (reduce, refine, replace). Dedicated workshops in this area will be offered and researchers from disciplines where animal research is relevant are particularly encouraged to apply.]]></summary></entry><entry xml:lang="english"><title type="html">Reproducibility of neuroimaging studies of brain disorders with hundreds -not thousands- of participants</title><link href="https://www.recherche-reproductible.fr/FR-RN/publication/2022/07/07/Reproducibility-of-Neuroimaging-Studies.html" rel="alternate" type="text/html" title="Reproducibility of neuroimaging studies of brain disorders with hundreds -not thousands- of participants" /><published>2022-07-07T14:00:00+00:00</published><updated>2022-07-07T14:00:00+00:00</updated><id>https://www.recherche-reproductible.fr/FR-RN/publication/2022/07/07/Reproducibility-of-Neuroimaging-Studies</id><content type="html" xml:base="https://www.recherche-reproductible.fr/FR-RN/publication/2022/07/07/Reproducibility-of-Neuroimaging-Studies.html"><![CDATA[<p>An important current question in neuroimaging concerns the sample sizes required for producing reliable and reproducible results. Recent findings suggest that brain-wide association studies (BWAS) linking neuroimaging features with behavioural phenotypes in the general population are characterised by (very) weak effects and consequently need large samples sizes of 3000+ to lead to reproducible findings. A second, important goal in neuroimaging is to study brain structure and function under disease conditions, where effects are likely much larger. This difference in effect size is important. We show by means of power calculations and empirical analysis that neuroimaging studies in clinical populations need hundreds -and not necessarily thousands-of participants to lead to reproducible findings.</p>

<p><a href="https://www.biorxiv.org/content/10.1101/2022.07.05.498443v1?rss=1">(missing reference)</a></p>]]></content><author><name>Recherche Reproductible</name></author><category term="publication" /><category term="neuroimaging" /><summary type="html"><![CDATA[An important current question in neuroimaging concerns the sample sizes required for producing reliable and reproducible results. Recent findings suggest that brain-wide association studies (BWAS) linking neuroimaging features with behavioural phenotypes in the general population are characterised by (very) weak effects and consequently need large samples sizes of 3000+ to lead to reproducible findings. A second, important goal in neuroimaging is to study brain structure and function under disease conditions, where effects are likely much larger. This difference in effect size is important. We show by means of power calculations and empirical analysis that neuroimaging studies in clinical populations need hundreds -and not necessarily thousands-of participants to lead to reproducible findings.]]></summary></entry><entry xml:lang="english"><title type="html">Reproducibility of in-vivo electrophysiological measurements in mice</title><link href="https://www.recherche-reproductible.fr/FR-RN/publication/2022/05/09/reproducibility-in-vivo.html" rel="alternate" type="text/html" title="Reproducibility of in-vivo electrophysiological measurements in mice" /><published>2022-05-09T14:00:00+00:00</published><updated>2022-05-09T14:00:00+00:00</updated><id>https://www.recherche-reproductible.fr/FR-RN/publication/2022/05/09/reproducibility-in-vivo</id><content type="html" xml:base="https://www.recherche-reproductible.fr/FR-RN/publication/2022/05/09/reproducibility-in-vivo.html"><![CDATA[<p>Understanding whole-brain-scale electrophysiological recordings will rely on the collective work of multiple labs. Because two labs recording from the same brain area often reach different conclusions, it is critical to quantify and control for features that decrease reproducibility. To address these issues, we formed a multi-lab collaboration using a shared, open-source behavioral task and experimental apparatus. We repeatedly inserted Neuropixels multi-electrode probes targeting the same brain locations (including posterior parietal cortex, hippocampus, and thalamus) in mice performing the behavioral task. We gathered data across 9 labs and developed a common histological and data processing pipeline to analyze the resulting large datasets. After applying stringent behavioral, histological, and electrophysiological quality-control criteria, we found that neuronal yield, firing rates, spike amplitudes, and task-modulated neuronal activity were reproducible across laboratories. To quantify variance in neural activity explained by task variables (e.g., stimulus onset time), behavioral variables (timing of licks/paw movements), and other variables (e.g., spatial location in the brain or the lab ID), we developed a multi-task neural network encoding model that extends common, simpler regression approaches by allowing nonlinear interactions between variables. We found that within-lab random effects captured by this model were comparable to between-lab random effects. Taken together, these results demonstrate that across-lab standardization of electrophysiological procedures can lead to reproducible results across labs. Moreover, our protocols to achieve reproducibility, along with our analyses to evaluate it are openly accessible to the scientific community, along with our extensive electrophysiological dataset with corresponding behavior and open-source analysis code.</p>

<p><a href="https://www.biorxiv.org/content/10.1101/2022.05.09.491042v1"><span id="IBL:2022"><span style="font-variant: small-caps">Laboratory, I.B., Banga, K., Benson, J., et al.</span> 2022. Reproducibility of in-vivo electrophysiological measurements in mice. <i>bioRxiv</i>.</span></a></p>]]></content><author><name>Recherche Reproductible</name></author><category term="publication" /><category term="neuroscience" /><summary type="html"><![CDATA[Understanding whole-brain-scale electrophysiological recordings will rely on the collective work of multiple labs. Because two labs recording from the same brain area often reach different conclusions, it is critical to quantify and control for features that decrease reproducibility. To address these issues, we formed a multi-lab collaboration using a shared, open-source behavioral task and experimental apparatus. We repeatedly inserted Neuropixels multi-electrode probes targeting the same brain locations (including posterior parietal cortex, hippocampus, and thalamus) in mice performing the behavioral task. We gathered data across 9 labs and developed a common histological and data processing pipeline to analyze the resulting large datasets. After applying stringent behavioral, histological, and electrophysiological quality-control criteria, we found that neuronal yield, firing rates, spike amplitudes, and task-modulated neuronal activity were reproducible across laboratories. To quantify variance in neural activity explained by task variables (e.g., stimulus onset time), behavioral variables (timing of licks/paw movements), and other variables (e.g., spatial location in the brain or the lab ID), we developed a multi-task neural network encoding model that extends common, simpler regression approaches by allowing nonlinear interactions between variables. We found that within-lab random effects captured by this model were comparable to between-lab random effects. Taken together, these results demonstrate that across-lab standardization of electrophysiological procedures can lead to reproducible results across labs. Moreover, our protocols to achieve reproducibility, along with our analyses to evaluate it are openly accessible to the scientific community, along with our extensive electrophysiological dataset with corresponding behavior and open-source analysis code.]]></summary></entry><entry xml:lang="english"><title type="html">Share the code, not just the data: A case study of the reproducibility of articles published in the Journal of Memory and Language under the open data policy</title><link href="https://www.recherche-reproductible.fr/FR-RN/publication/2022/04/18/share-the-code.html" rel="alternate" type="text/html" title="Share the code, not just the data: A case study of the reproducibility of articles published in the Journal of Memory and Language under the open data policy" /><published>2022-04-18T14:00:00+00:00</published><updated>2022-04-18T14:00:00+00:00</updated><id>https://www.recherche-reproductible.fr/FR-RN/publication/2022/04/18/share-the-code</id><content type="html" xml:base="https://www.recherche-reproductible.fr/FR-RN/publication/2022/04/18/share-the-code.html"><![CDATA[<p>In 2019 the Journal of Memory and Language instituted an open data and code policy; this policy requires that, as a rule, code and data be released at the latest upon publication. How effective is this policy? We compared 59 papers published before, and 59 papers published after, the policy took effect. After the policy was in place, the rate of data sharing increased by more than 50%. We further looked at whether papers published under the open data policy were reproducible, in the sense that the published results should be possible to regenerate given the data, and given the code, when code was provided. For 8 out of the 59 papers, data sets were inaccessible. The reproducibility rate ranged from 34% to 56%, depending on the reproducibility criteria. The strongest predictor of whether an attempt to reproduce would be successful is the presence of the analysis code: it increases the probability of reproducing reported results by almost 40%. We propose two simple steps that can increase the reproducibility of published papers: share the analysis code, and attempt to reproduce one’s own analysis using only the shared materials.</p>

<p><a href="https://psyarxiv.com/hf297/"><span id="Laurinavichyute:2022"><span style="font-variant: small-caps">Laurinavichyute, A., Yadav, H., and Vasishth, S.</span> 2021. Share the code,  not just the data: A case study of the reproducibility of articles published in the Journal of Memory and Language under the open data policy. .</span></a></p>]]></content><author><name>Recherche Reproductible</name></author><category term="publication" /><category term="cognitive" /><category term="science" /><summary type="html"><![CDATA[In 2019 the Journal of Memory and Language instituted an open data and code policy; this policy requires that, as a rule, code and data be released at the latest upon publication. How effective is this policy? We compared 59 papers published before, and 59 papers published after, the policy took effect. After the policy was in place, the rate of data sharing increased by more than 50%. We further looked at whether papers published under the open data policy were reproducible, in the sense that the published results should be possible to regenerate given the data, and given the code, when code was provided. For 8 out of the 59 papers, data sets were inaccessible. The reproducibility rate ranged from 34% to 56%, depending on the reproducibility criteria. The strongest predictor of whether an attempt to reproduce would be successful is the presence of the analysis code: it increases the probability of reproducing reported results by almost 40%. We propose two simple steps that can increase the reproducibility of published papers: share the analysis code, and attempt to reproduce one’s own analysis using only the shared materials.]]></summary></entry><entry xml:lang="english"><title type="html">Methodology over metrics: current scientific standards are a disservice to patients and society</title><link href="https://www.recherche-reproductible.fr/FR-RN/publication/2022/04/17/Methodology-over-metrics.html" rel="alternate" type="text/html" title="Methodology over metrics: current scientific standards are a disservice to patients and society" /><published>2022-04-17T14:00:00+00:00</published><updated>2022-04-17T14:00:00+00:00</updated><id>https://www.recherche-reproductible.fr/FR-RN/publication/2022/04/17/Methodology-over-metrics</id><content type="html" xml:base="https://www.recherche-reproductible.fr/FR-RN/publication/2022/04/17/Methodology-over-metrics.html"><![CDATA[<p>Covid-19 research made it painfully clear that the scandal of poor medical research, as denounced by Altman in 1994, persists today. The overall quality of medical research remains poor, despite longstanding criticisms. The problems are well known, but the research community fails to properly address them. We suggest that most problems stem from an underlying paradox: although methodology is undeniably the backbone of high-quality and responsible research, science consistently undervalues methodology. The focus remains more on the destination (research claims and metrics) than on the journey. Notwithstanding, research should serve society more than the reputation of those involved. While we notice that many initiatives are being established to improve components of the research cycle, these initiatives are too disjointed. The overall system is monolithic and slow to adapt. We assert that top-down action is needed from journals, universities, funders and governments to break the cycle and put methodology first. These actions should involve the widespread adoption of registered reports, balanced research funding between innovative, incremental and methodological research projects, full recognition and demystification of peer review, improved methodological review of reports, adherence to reporting guidelines, and investment in methodological education and research. Currently, the scientific enterprise is doing a major disservice to patients and society.</p>

<p><a href="https://www.jclinepi.com/article/S0895-4356(21)00170-0/fulltext"><span id="VanCalster:2021"><span style="font-variant: small-caps">Van Calster, B., Wynants, L., Riley, R.D., Smeden, M. van, and Collins, G.S.</span> 2021. Methodology over metrics: current scientific
                  standards are a disservice to patients and society. <i>Journal of Clinical Epidemiology</i> <i>138</i>, 219–226.</span></a></p>]]></content><author><name>Recherche Reproductible</name></author><category term="publication" /><category term="medicine" /><summary type="html"><![CDATA[Covid-19 research made it painfully clear that the scandal of poor medical research, as denounced by Altman in 1994, persists today. The overall quality of medical research remains poor, despite longstanding criticisms. The problems are well known, but the research community fails to properly address them. We suggest that most problems stem from an underlying paradox: although methodology is undeniably the backbone of high-quality and responsible research, science consistently undervalues methodology. The focus remains more on the destination (research claims and metrics) than on the journey. Notwithstanding, research should serve society more than the reputation of those involved. While we notice that many initiatives are being established to improve components of the research cycle, these initiatives are too disjointed. The overall system is monolithic and slow to adapt. We assert that top-down action is needed from journals, universities, funders and governments to break the cycle and put methodology first. These actions should involve the widespread adoption of registered reports, balanced research funding between innovative, incremental and methodological research projects, full recognition and demystification of peer review, improved methodological review of reports, adherence to reporting guidelines, and investment in methodological education and research. Currently, the scientific enterprise is doing a major disservice to patients and society.]]></summary></entry><entry xml:lang="english"><title type="html">Overcoming the Reproducibility Crisis - Results of the first Community Survey of the German National Research Data Infrastructure for Neuroscience</title><link href="https://www.recherche-reproductible.fr/FR-RN/publication/2022/04/11/Overcoming-reproducibility-crisis.html" rel="alternate" type="text/html" title="Overcoming the Reproducibility Crisis - Results of the first Community Survey of the German National Research Data Infrastructure for Neuroscience" /><published>2022-04-11T14:00:00+00:00</published><updated>2022-04-11T14:00:00+00:00</updated><id>https://www.recherche-reproductible.fr/FR-RN/publication/2022/04/11/Overcoming-reproducibility-crisis</id><content type="html" xml:base="https://www.recherche-reproductible.fr/FR-RN/publication/2022/04/11/Overcoming-reproducibility-crisis.html"><![CDATA[<p>The lack of reproducibility of research results is a serious problem - known as “the reproducibility crisis”. The German National Research Data Infrastructure (NFDI) initiative implemented by the German Research Foundation (DFG) aims to help overcoming this crisis by developing sustainable solutions for research data management (RDM). NFDI comprises domain specific consortia across all science disciplines. In the field of neuroscience, NFDI Neuroscience (NFDI-Neuro) contributes to the strengthening of systematic and standardized RDM in its research communities. NFDI-Neuro conducted a comprehensive survey amongst the neuroscience community to determine the current needs, challenges, and opinions with respect to RDM. The outcomes of this survey are presented here. The German neuroscience community perceives barriers with respect to RDM and data sharing mainly linked to (1) lack of data and metadata standards, (2) lack of community adopted provenance tracking methods, 3) lack of a privacy preserving research infrastructure for sensitive data (4) lack of RDM literacy and (5) lack of required time and resources for proper RDM. NFDI-Neuro aims to systematically address these barriers by leading and contributing to the development of standards, tools, and infrastructure and by providing training, education and support, as well as additional resources to its research community. The RDM work of NFDI-Neuro is conducted in close collaboration with its partner EBRAINS AISBL, the coordinating entity of the EU Flagship Human Brain Project, and its Research Infrastructure (RI) EBRAINS with more than 4500 registered users and developers from more than 30 countries. While NFDI-Neuro aims to address the national needs, it closely aligns with the international community and the topics of the Digital Europe Program and EU Data Spaces.</p>

<p><a href="https://www.biorxiv.org/content/10.1101/2022.04.07.487439v1"><span id="Klingner:2022"><span style="font-variant: small-caps">Klingner, C.M., Denker, M., Grün, S., et al.</span> 2022. Overcoming the Reproducibility Crisis - Results of
                  the first Community Survey of the German National
                  Research Data Infrastructure for Neuroscience. .</span></a></p>]]></content><author><name>Recherche Reproductible</name></author><category term="publication" /><category term="neuroscience" /><summary type="html"><![CDATA[The lack of reproducibility of research results is a serious problem - known as “the reproducibility crisis”. The German National Research Data Infrastructure (NFDI) initiative implemented by the German Research Foundation (DFG) aims to help overcoming this crisis by developing sustainable solutions for research data management (RDM). NFDI comprises domain specific consortia across all science disciplines. In the field of neuroscience, NFDI Neuroscience (NFDI-Neuro) contributes to the strengthening of systematic and standardized RDM in its research communities. NFDI-Neuro conducted a comprehensive survey amongst the neuroscience community to determine the current needs, challenges, and opinions with respect to RDM. The outcomes of this survey are presented here. The German neuroscience community perceives barriers with respect to RDM and data sharing mainly linked to (1) lack of data and metadata standards, (2) lack of community adopted provenance tracking methods, 3) lack of a privacy preserving research infrastructure for sensitive data (4) lack of RDM literacy and (5) lack of required time and resources for proper RDM. NFDI-Neuro aims to systematically address these barriers by leading and contributing to the development of standards, tools, and infrastructure and by providing training, education and support, as well as additional resources to its research community. The RDM work of NFDI-Neuro is conducted in close collaboration with its partner EBRAINS AISBL, the coordinating entity of the EU Flagship Human Brain Project, and its Research Infrastructure (RI) EBRAINS with more than 4500 registered users and developers from more than 30 countries. While NFDI-Neuro aims to address the national needs, it closely aligns with the international community and the topics of the Digital Europe Program and EU Data Spaces.]]></summary></entry></feed>